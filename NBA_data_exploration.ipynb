{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Lookup how to create dictionaries and then access them throughout the program\n",
    "\n",
    "team_list = ['GSW', 'HOU', 'OKC', 'SAC', 'CLE', 'POR', 'NOP', 'TOR', 'IND', \n",
    "         'BOS', 'NYK', 'LAC', 'SAS', 'CHI', 'CHA', 'MIN', 'BKN', 'PHX', \n",
    "         'WAS', 'UTA', 'DEN', 'MIA', 'DET', 'DAL', 'ORL', 'MIL', 'LAL', \n",
    "         'PHI', 'ATL', 'MEM']\n",
    "\n",
    "file = 'players/nba_player_1516.csv'\n",
    "\n",
    "def build_player_dictionary(file):\n",
    "    \n",
    "    data = pd.read_csv(file, index_col=0)\n",
    "    \n",
    "    team_dict = {}\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        team = row['TEAM']\n",
    "        name = row['PLAYER']\n",
    "\n",
    "        row_as_dict = row.to_dict()\n",
    "\n",
    "        if team_dict.get(team) is None:\n",
    "            team_dict[team] = {}\n",
    "            team_dict[team][name] = row_as_dict\n",
    "        else:\n",
    "            team_dict[team][name] = row_as_dict\n",
    "    return team_dict\n",
    "\n",
    "# players_dict_1516 = build_player_dictionary(file)\n",
    "\n",
    "# print(players_dict_1516.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_team_dictionary(file):\n",
    "    data = pd.read_csv(file, index_col=0)\n",
    "    team_dict = {}\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        team = row['TEAM']\n",
    "        stats = row.to_dict()\n",
    "        \n",
    "        team_dict[team] = stats\n",
    "        \n",
    "    return team_dict\n",
    "\n",
    "# file = 'teams/nba_team_1011.csv'\n",
    "\n",
    "# mydict = build_team_dictionary(file)\n",
    "\n",
    "# print(mydict['Chicago Bulls'].keys())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(players_dict_1516.get('HOU').get('James Harden').keys())\n",
    "\n",
    "cols_drop = ['PLAYER', 'TEAM']  # all other columns are relevant\n",
    "\n",
    "drop_list = ['PLAYER', 'TEAM', 'W', 'L', 'MIN', 'FGM', 'FGA', '3PM', '3PA', 'FTM', 'FTA', 'OREB', 'DREB', 'PF', 'FP', 'DD2', 'TD3']\n",
    "\n",
    "player_stats = ['PLAYER', 'TEAM', 'AGE', 'GP', 'W', 'L', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3PM', '3PA', '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'TOV', 'STL', 'BLK', 'PF', 'FP', 'DD2', 'TD3', '+/-']\n",
    "\n",
    "team_stats = ['TEAM', 'GP', 'W', 'L', 'WIN%', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3PM', '3PA', '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'TOV', 'STL', 'BLK', 'BLKA', 'PF', 'PFD', '+/-']\n",
    "\n",
    "team_drop = ['TEAM', 'GP', 'W', 'L', 'MIN', 'FGM', 'FGA', '3PM', '3PA', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'BLKA', 'PF', 'PFD']\n",
    "\n",
    "player_keep = [x for x in player_stats if x not in drop_list]\n",
    "team_keep = [x for x in team_stats if x not in team_drop]\n",
    "\n",
    "\n",
    "def top_players_vec(team):\n",
    "    team_df = pd.DataFrame.from_dict(team)  # column == player == feature vector (need to drop name/team) \n",
    "    # select top 8 players with most minutes:\n",
    "    # sort based on minutes played\n",
    "    team_df = team_df.sort_values('MIN', axis=1, ascending=False)\n",
    "    team_df = team_df.drop(['PLAYER', 'TEAM'])\n",
    "    team_df = team_df.iloc[:,0:8]\n",
    "    #print('player stats columns:', team_df.index.values)\n",
    "    team_vec = team_df.values\n",
    "    team_vec = np.array(team_vec).ravel()\n",
    "    return team_vec\n",
    "\n",
    "\n",
    "def team_stats_vec(team):\n",
    "    #print(team)\n",
    "    #team_df = pd.DataFrame.from_dict(team)\n",
    "    team_df = pd.DataFrame(team, index=[0])\n",
    "    team_df = team_df.drop(team_drop, axis=1)\n",
    "    #print('team stats columns:', team_df.columns.values)\n",
    "    team_vec = team_df.values\n",
    "    return team_vec[0]\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# headers for player stats\n",
    "#['+/-' '3P%' '3PA' '3PM' 'AGE' 'AST' 'BLK' 'DD2' 'DREB' 'FG%' 'FGA' 'FGM'\n",
    "# 'FP' 'FT%' 'FTA' 'FTM' 'GP' 'L' 'MIN' 'OREB' 'PF' 'PTS' 'REB' 'STL' 'TD3'\n",
    "# 'TOV' 'W']\n",
    "\n",
    "# headers for team stats\n",
    "# ['+/-' '3P%' 'AST' 'BLK' 'FG%' 'PTS' 'REB' 'STL' 'TOV' 'WIN%']\n",
    "team_headers = ['+/-', '3P%', 'AST', 'BLK', 'FG%', 'PTS', 'REB', 'STL', 'TOV', 'WIN%']\n",
    "player_headers = ['+/-', '3P%', '3PA', '3PM', 'AGE', 'AST', 'BLK', 'DD2', 'DREB', 'FG%', 'FGA', 'FGM',\n",
    "                  'FP', 'FT%', 'FTA', 'FTM', 'GP', 'L', 'MIN', 'OREB', 'PF', 'PTS', 'REB', 'STL', 'TD3',\n",
    "                  'TOV', 'W']\n",
    "# Long NBA team name to abbreviations dictionary\n",
    "team_name_dict = {}\n",
    "team_name_dict['Houston Rockets'] = 'HOU'\n",
    "team_name_dict['Toronto Raptors'] = 'TOR'\n",
    "team_name_dict['Golden State Warriors'] = 'GSW'\n",
    "team_name_dict['Boston Celtics'] = 'BOS'\n",
    "team_name_dict['Philadelphia 76ers'] = 'PHI'\n",
    "team_name_dict['Cleveland Cavaliers'] = 'CLE'\n",
    "team_name_dict['Portland Trail Blazers'] = 'POR'\n",
    "team_name_dict['Indiana Pacers'] = 'IND'\n",
    "team_name_dict['Oklahoma City Thunder'] = 'OKC'\n",
    "team_name_dict['New Orleans Pelicans'] = 'NOP'\n",
    "team_name_dict['Utah Jazz'] = 'UTA'\n",
    "team_name_dict['San Antonio Spurs'] = 'SAS'\n",
    "team_name_dict['Minnesota Timberwolves'] = 'MIN'\n",
    "team_name_dict['Denver Nuggets'] = 'DEN'\n",
    "team_name_dict['Miami Heat'] = 'MIA'\n",
    "team_name_dict['Milwaukee Bucks'] = 'MIL'\n",
    "team_name_dict['Washington Wizards'] = 'WAS'\n",
    "team_name_dict['Los Angeles Clippers'] = 'LAC'\n",
    "team_name_dict['Detroit Pistons'] = 'DET'\n",
    "team_name_dict['Charlotte Hornets'] = 'CHA'\n",
    "team_name_dict['Los Angeles Lakers'] = 'LAL'\n",
    "team_name_dict['New York Knicks'] = 'NYK'\n",
    "team_name_dict['Brooklyn Nets'] = 'BKN'\n",
    "team_name_dict['Sacramento Kings'] = 'SAC'\n",
    "team_name_dict['Chicago Bulls'] = 'CHI'\n",
    "team_name_dict['Orlando Magic'] = 'ORL'\n",
    "team_name_dict['Dallas Mavericks'] = 'DAL'\n",
    "team_name_dict['Atlanta Hawks'] = 'ATL'\n",
    "team_name_dict['Memphis Grizzlies'] = 'MEM'\n",
    "team_name_dict['Phoenix Suns'] = 'PHX'\n",
    "team_name_dict['Vancouver Grizzlies'] = 'VAN'\n",
    "team_name_dict['Seattle SuperSonics'] = 'SEA'\n",
    "team_name_dict['New Jersey Nets'] = 'NJN'\n",
    "team_name_dict['Charlotte Hornets'] = 'CHH' # last season was 2001-02 -> new orleans hornets\n",
    "team_name_dict['Charlotte Hornets 2'] = 'CHA' # 1415 seaons onwards need to edit csvs\n",
    "team_name_dict['Charlotte Bobcats'] = 'CHB' # last season was 2013-14 -> charlotte hornets (changed back)\n",
    "team_name_dict['New Orleans Hornets'] = 'NOH' # last season was 2012-2013 COULD ALSO BE NOK!!!\n",
    "\n",
    "name_reverse_dictionary = {}\n",
    "for key, value in team_name_dict.items():\n",
    "    name_reverse_dictionary[value] = key\n",
    "    \n",
    "name_reverse_dictionary['NOK'] = 'New Orleans Hornets'\n",
    "name_reverse_dictionary['NOH'] = 'New Orleans Hornets'\n",
    "name_reverse_dictionary['CHA'] = 'Charlotte Hornets'\n",
    "\n",
    "# prepare data\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "team_folder = cwd+'/teams/'\n",
    "player_folder = cwd+'/players/'\n",
    "\n",
    "teams_dict = {}\n",
    "players_dict = {}\n",
    "\n",
    "def get_next_season(season):\n",
    "    beginning = int(season[:2])\n",
    "    year = None\n",
    "    if beginning < 20:\n",
    "        year = beginning + 2000\n",
    "    else:\n",
    "        year = beginning + 1900\n",
    "    return str(year+1)[2:] + str(year+2)[2:]\n",
    "\n",
    "team_list = ['Houston Rockets', 'Toronto Raptors', 'Golden State Warriors', 'Boston Celtics', 'Philadelphia 76ers', \n",
    "             'Cleveland Cavaliers', 'Portland Trail Blazers', 'Indiana Pacers', 'Oklahoma City Thunder', \n",
    "             'New Orleans Pelicans', 'Utah Jazz', 'San Antonio Spurs', 'Minnesota Timberwolves', 'Denver Nuggets', \n",
    "             'Miami Heat', 'Milwaukee Bucks', 'Washington Wizards', 'Los Angeles Clippers', 'Detroit Pistons', 'Charlotte Hornets',\n",
    "             'Los Angeles Lakers', 'New York Knicks', 'Brooklyn Nets', 'Sacramento Kings', 'Chicago Bulls', \n",
    "             'Orlando Magic', 'Dallas Mavericks', 'Atlanta Hawks', 'Memphis Grizzlies', 'Phoenix Suns']\n",
    "\n",
    "\n",
    "def get_short_name(team):\n",
    "    return team_name_dict.get(team)\n",
    "\n",
    "def get_long_name(team):\n",
    "    return name_reverse_dictionary.get(team)\n",
    "\n",
    "def name_conversion(team):\n",
    "    team_dict = {}\n",
    "    team_dict['Vancouver Grizzlies'] = 'Memphis Grizzlies'\n",
    "    team_dict['Charlotte Hornets'] = 'New Orleans Hornets'\n",
    "    team_dict['Seattle SuperSonics'] = 'Oklahoma City Thunder'\n",
    "    team_dict['New Jersey Nets'] = 'Brooklyn Nets'\n",
    "    team_dict['New Orleans Hornets'] = 'New Orleans Pelicans'\n",
    "    team_dict['Charlotte Bobcats'] = 'Charlotte Hornets'\n",
    "    return team_dict.get(team)\n",
    "\n",
    "def next_season_team(team_long, season):\n",
    "    new_team = team_long\n",
    "    \n",
    "    if season == '0001' and team_long == 'Vancouver Grizzlies':\n",
    "        new_team = name_conversion(team_long)\n",
    "    elif season == '0102' and team_long == 'Charlotte Hornets':\n",
    "        new_team = name_conversion(team_long)\n",
    "    elif season == '0708' and team_long == 'Seattle SuperSonics':\n",
    "        new_team = name_conversion(team_long)\n",
    "    elif season == '1112' and team_long == 'New Jersey Nets':\n",
    "        new_team = name_conversion(team_long)\n",
    "    elif season == '1314' and team_long == 'Charlotte Bobcats':\n",
    "        new_team = name_conversion(team_long)\n",
    "    elif season == '1213' and team_long =='New Orleans Hornets':\n",
    "        new_team = name_conversion(team_long)\n",
    "    \n",
    "    return new_team\n",
    "\n",
    "def build_dictionaries():\n",
    "    print('Building dictionaries...')\n",
    "    \n",
    "    for file in os.listdir(team_folder):\n",
    "        season = str(file[-8:-4])\n",
    "        season_teams = build_team_dictionary(team_folder+file)\n",
    "        #print(season_teams.keys())\n",
    "        teams_dict[season] = season_teams\n",
    "\n",
    "    for file in os.listdir(player_folder):\n",
    "        season = str(file[-8:-4])\n",
    "        season_players = build_player_dictionary(player_folder+file)\n",
    "        player_dict = {}\n",
    "        players_dict[season] = season_players\n",
    "        \n",
    "    print('Done building dictionaries.')\n",
    "\n",
    "    print(players_dict.keys())\n",
    "    print(teams_dict.keys())\n",
    "\n",
    "build_dictionaries()\n",
    "    \n",
    "\n",
    "num_seasons = len(players_dict)\n",
    "\n",
    "\n",
    "highest_season = '1718'\n",
    "print(num_seasons)\n",
    "\n",
    "def feature_gen():\n",
    "    print('Generating features...')\n",
    "    i = 0\n",
    "    if len(teams_dict) == 0:\n",
    "        build_dictionaries()\n",
    "    \n",
    "    x_vec_length = None\n",
    "\n",
    "    x_matrix = pd.DataFrame({})\n",
    "    y_vec = []\n",
    "    \n",
    "    for season, t_dict in players_dict.items():\n",
    "        i += 1\n",
    "        #print(season)\n",
    "        #print(get_next_season(season))\n",
    "        if i >= num_seasons-1 or season == highest_season:\n",
    "            continue\n",
    "\n",
    "        next_season = get_next_season(season)\n",
    "\n",
    "        # for each season, generate feature vectors for each team\n",
    "        for t, t_stats in t_dict.items():\n",
    "            plyr_vec = top_players_vec(t_stats)\n",
    "\n",
    "            next_season_tname = next_season_team(get_long_name(t), season)\n",
    "            if get_long_name(t) == 'LA Clippers':\n",
    "                print(season)\n",
    "                print('LA Clippers')\n",
    "            try:\n",
    "                team_vec = team_stats_vec(teams_dict[season][get_long_name(t)])\n",
    "            except Exception as e:\n",
    "                print('Ignoring case')\n",
    "                print('team', t)\n",
    "                print('error', e)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                next_team_vec = team_stats_vec(teams_dict[next_season][next_season_tname])\n",
    "            except Exception as e:\n",
    "                print('Ignoring case')\n",
    "                print(e)\n",
    "                continue\n",
    "            # create performance categories for win percentage\n",
    "            next_s_t_winp = next_team_vec[-1]  # index for the win%\n",
    "            if next_s_t_winp >= 0.8:\n",
    "                next_s_t_winp = 4\n",
    "            elif next_s_t_winp >= 0.6:\n",
    "                next_s_t_winp = 3\n",
    "            elif next_s_t_winp >= 0.4:\n",
    "                next_s_t_winp = 2\n",
    "            elif next_s_t_winp >= 0.2:\n",
    "                next_s_t_winp = 1\n",
    "            else:\n",
    "                next_s_t_winp = 0\n",
    "\n",
    "#             print('plyr_vec', plyr_vec)\n",
    "#             print('team_vec', team_vec)\n",
    "#             print('next_team_vec', next_team_vec)\n",
    "\n",
    "            # Create headers\n",
    "            player_h_portion = [[x+'_1', x+'_2', x+'_3', x+'_4', x+'_5', x+'_6', x+'_7', x+'_8'] for x in player_headers]\n",
    "            player_labels = []\n",
    "            for l in player_h_portion:\n",
    "                player_labels += l\n",
    "\n",
    "            curr_headers = team_headers+player_labels\n",
    "\n",
    "            x_vec = np.concatenate((team_vec, plyr_vec))\n",
    "            #print(x_vec)\n",
    "            x_series = pd.DataFrame(np.reshape(x_vec, (1,len(x_vec))), columns = curr_headers)\n",
    "            #print(x_series)\n",
    "            x_vec_label = next_s_t_winp  # set label\n",
    "\n",
    "            #x_matrix.extend(x_series)\n",
    "            x_matrix = pd.concat([x_matrix, x_series], ignore_index=True)\n",
    "            y_vec.append(x_vec_label)\n",
    "\n",
    "            x_vec_length = len(x_vec)  # this needs to only be executed once\n",
    "\n",
    "    xdf = pd.DataFrame(x_matrix)\n",
    "    print(xdf)\n",
    "    ydf = pd.DataFrame(y_vec)\n",
    "    print(len(x_matrix))\n",
    "    print(players_dict.keys())\n",
    "    print('Done generating features.')\n",
    "    \n",
    "    return xdf, ydf\n",
    "\n",
    "xdf, ydf = feature_gen()\n",
    "\n",
    "xdf.to_csv('x_matrix.csv', sep=',')\n",
    "ydf.to_csv('y_vec.csv', sep=',')\n",
    "\n",
    "#print(len(x_matrix), len(x_matrix[0]))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "Xdf = pd.read_csv('x_matrix.csv', sep=',', dtype='float', index_col=0)\n",
    "ydf = pd.read_csv('y_vec.csv', sep=',', dtype='float', index_col=0)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xdf, ydf, test_size=0.2, random_state=20)\n",
    "\n",
    "# Create linear regression object\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "nba_y_pred = lm.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', lm.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, nba_y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, nba_y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Xdf = pd.read_csv('x_matrix.csv', sep=',', dtype='float', index_col=0)\n",
    "Xdf = Xdf.values\n",
    "ydf = pd.read_csv('y_vec.csv', sep=',', dtype='float', index_col=0)\n",
    "ydf = np.array(ydf).ravel()\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xdf, ydf, test_size=0.3, random_state=20)\n",
    "\n",
    "grid = {'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [200, 600, 1000],\n",
    "                  'max_depth': [5,10,20]}\n",
    "\n",
    "model = GridSearchCV(estimator=XGBClassifier(), param_grid=grid, cv=3)\n",
    "\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "print('Test accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Train accuracy:', accuracy_score(y_train, y_pred_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Train accuracy:', accuracy_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model file\n",
    "import pickle\n",
    "pickle.dump(model, open(\"model.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "Xdf = pd.read_csv('x_matrix.csv', sep=',', dtype='float', index_col=0)\n",
    "ydf = pd.read_csv('y_vec.csv', sep=',', dtype='int32', index_col=0)\n",
    "\n",
    "Xdf = Xdf.values\n",
    "ydf = np.array(ydf).ravel()\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = ydf.reshape(len(ydf), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xdf, onehot_encoded, test_size=0.3, random_state=20)\n",
    "input_dim = len(X_train[0])\n",
    "\n",
    "# find number of categories\n",
    "num_categories = max(ydf)+1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(input_dim + 100, activation='relu'))\n",
    "model.add(Dense(input_dim + 100, activation='relu'))\n",
    "model.add(Dense(input_dim, activation='relu'))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=1)\n",
    "scores = model.evaluate(x=X_test,y=y_test)\n",
    "print(\"Model performance:\")\n",
    "print(\"%s,%.3f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
