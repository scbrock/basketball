{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stephenbrock/Documents/github/basketball\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create dictionaries and then access them throughout the program\n",
    "\n",
    "team_list = ['GSW', 'HOU', 'OKC', 'SAC', 'CLE', 'POR', 'NOP', 'TOR', 'IND', \n",
    "         'BOS', 'NYK', 'LAC', 'SAS', 'CHI', 'CHA', 'MIN', 'BKN', 'PHX', \n",
    "         'WAS', 'UTA', 'DEN', 'MIA', 'DET', 'DAL', 'ORL', 'MIL', 'LAL', \n",
    "         'PHI', 'ATL', 'MEM']\n",
    "\n",
    "file = 'players/nba_player_1516.csv'\n",
    "\n",
    "def build_player_dictionary(file):\n",
    "    \n",
    "    data = pd.read_csv(file, index_col=0)\n",
    "    \n",
    "    team_dict = {}\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        team = row['TEAM']\n",
    "        name = row['PLAYER']\n",
    "\n",
    "        row_as_dict = row.to_dict()\n",
    "\n",
    "        if team_dict.get(team) is None:\n",
    "            team_dict[team] = {}\n",
    "            team_dict[team][name] = row_as_dict\n",
    "        else:\n",
    "            team_dict[team][name] = row_as_dict\n",
    "    return team_dict\n",
    "\n",
    "# players_dict_1516 = build_player_dictionary(file)\n",
    "\n",
    "# print(players_dict_1516.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_team_dictionary(file):\n",
    "    data = pd.read_csv(file, index_col=0)\n",
    "    team_dict = {}\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        team = row['TEAM']\n",
    "        stats = row.to_dict()\n",
    "        \n",
    "        team_dict[team] = stats\n",
    "        \n",
    "    return team_dict\n",
    "\n",
    "# file = 'teams/nba_team_1011.csv'\n",
    "\n",
    "# mydict = build_team_dictionary(file)\n",
    "\n",
    "# print(mydict['Chicago Bulls'].keys())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(players_dict_1516.get('HOU').get('James Harden').keys())\n",
    "\n",
    "cols_drop = ['PLAYER', 'TEAM']  # all other columns are relevant\n",
    "\n",
    "drop_list = ['PLAYER', 'TEAM', 'W', 'L', 'MIN', 'FGM', 'FGA', '3PM', '3PA', 'FTM', 'FTA', 'OREB', 'DREB', 'PF', 'FP', 'DD2', 'TD3']\n",
    "\n",
    "player_stats = ['PLAYER', 'TEAM', 'AGE', 'GP', 'W', 'L', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3PM', '3PA', '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'TOV', 'STL', 'BLK', 'PF', 'FP', 'DD2', 'TD3', '+/-']\n",
    "\n",
    "team_stats = ['TEAM', 'GP', 'W', 'L', 'WIN%', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3PM', '3PA', '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'TOV', 'STL', 'BLK', 'BLKA', 'PF', 'PFD', '+/-']\n",
    "\n",
    "team_drop = ['TEAM', 'GP', 'W', 'L', 'MIN', 'FGM', 'FGA', '3PM', '3PA', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'BLKA', 'PF', 'PFD']\n",
    "\n",
    "player_keep = [x for x in player_stats if x not in drop_list]\n",
    "team_keep = [x for x in team_stats if x not in team_drop]\n",
    "\n",
    "\n",
    "# create top players feature vector\n",
    "def top_players_vec(team):\n",
    "    team_df = pd.DataFrame.from_dict(team)  # column == player == feature vector (need to drop name/team) \n",
    "    # select top 8 players with most minutes:\n",
    "    # sort based on minutes played\n",
    "    team_df = team_df.sort_values('MIN', axis=1, ascending=False)\n",
    "    team_df = team_df.drop(['PLAYER', 'TEAM'])\n",
    "    team_df = team_df.iloc[:,0:8]\n",
    "    #print('player stats columns:', team_df.index.values)\n",
    "    team_vec = team_df.values\n",
    "    team_vec = np.array(team_vec).ravel()\n",
    "    return team_vec\n",
    "\n",
    "# create team stats feature vector\n",
    "def team_stats_vec(team):\n",
    "    #print(team)\n",
    "    #team_df = pd.DataFrame.from_dict(team)\n",
    "    team_df = pd.DataFrame(team, index=[0])\n",
    "    team_df = team_df.drop(team_drop, axis=1)\n",
    "    #print('team stats columns:', team_df.columns.values)\n",
    "    team_vec = team_df.values\n",
    "    return team_vec[0]\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name_dict = {'Houston Rockets' : 'HOU',\n",
    "'Toronto Raptors' : 'TOR',\n",
    "'Golden State Warriors' : 'GSW',\n",
    "'Boston Celtics' : 'BOS',\n",
    "'Philadelphia 76ers' : 'PHI',\n",
    "'Cleveland Cavaliers' : 'CLE',\n",
    "'Portland Trail Blazers' : 'POR',\n",
    "'Indiana Pacers' : 'IND',\n",
    "'Oklahoma City Thunder' : 'OKC',\n",
    "'New Orleans Pelicans' : 'NOP',\n",
    "'Utah Jazz' : 'UTA',\n",
    "'San Antonio Spurs' : 'SAS',\n",
    "'Minnesota Timberwolves' : 'MIN',\n",
    "'Denver Nuggets' : 'DEN',\n",
    "'Miami Heat' : 'MIA',\n",
    "'Milwaukee Bucks' : 'MIL',\n",
    "'Washington Wizards' : 'WAS',\n",
    "'Los Angeles Clippers' : 'LAC',\n",
    "'Detroit Pistons' : 'DET',\n",
    "'Charlotte Hornets' : 'CHA',\n",
    "'Los Angeles Lakers' : 'LAL',\n",
    "'New York Knicks' : 'NYK',\n",
    "'Brooklyn Nets' : 'BKN',\n",
    "'Sacramento Kings' : 'SAC',\n",
    "'Chicago Bulls' : 'CHI',\n",
    "'Orlando Magic' : 'ORL',\n",
    "'Dallas Mavericks' : 'DAL',\n",
    "'Atlanta Hawks' : 'ATL',\n",
    "'Memphis Grizzlies' : 'MEM',\n",
    "'Phoenix Suns' : 'PHX',\n",
    "'Vancouver Grizzlies' : 'VAN',\n",
    "'Seattle SuperSonics' : 'SEA',\n",
    "'New Jersey Nets' : 'NJN',\n",
    "'Charlotte Hornets' : 'CHH', \n",
    "'Charlotte Hornets 2' : 'CHA', \n",
    "'Charlotte Bobcats' : 'CHB', \n",
    "'New Orleans Hornets' : 'NOH'}\n",
    "\n",
    "# last season was 2001-02 -> new orleans hornets\n",
    "# 1415 seaons onwards need to edit csvs\n",
    "# last season was 2013-14 -> charlotte hornets (changed back)\n",
    "# last season was 2012-2013 COULD ALSO BE NOK!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dictionaries...\n",
      "Done building dictionaries.\n",
      "dict_keys(['1516', '1112', '9798', '1314', '1011', '1213', '1415', '0910', '1617', '0708', '9900', '0304', '0102', '9697', '0506', '9899', '0405', '0607', '0001', '0203', '0809', '1718'])\n",
      "dict_keys(['1718', '0001', '0203', '0405', '0607', '0809', '0304', '9900', '0506', '9697', '0102', '9899', '0708', '0910', '1415', '1617', '1011', '1213', '9798', '1112', '1516', '1314'])\n",
      "22\n",
      "Generating features...\n",
      "Ignoring case\n",
      "team CHA\n",
      "error 'Charlotte Hornets'\n",
      "Ignoring case\n",
      "team CHA\n",
      "error 'Charlotte Hornets'\n",
      "Ignoring case\n",
      "team CHA\n",
      "error 'Charlotte Hornets'\n",
      "Ignoring case\n",
      "team CHA\n",
      "error 'Charlotte Hornets'\n",
      "Ignoring case\n",
      "team CHA\n",
      "error 'Charlotte Hornets'\n",
      "Ignoring case\n",
      "team CHA\n",
      "error 'Charlotte Hornets'\n",
      "Ignoring case\n",
      "team CHA\n",
      "error 'Charlotte Hornets'\n",
      "Ignoring case\n",
      "team CHA\n",
      "error 'Charlotte Hornets'\n",
      "Ignoring case\n",
      "team CHA\n",
      "error 'Charlotte Hornets'\n",
      "Ignoring case\n",
      "team nan\n",
      "error None\n",
      "Ignoring case\n",
      "team WAS\n",
      "error 'Washington Wizards'\n",
      "Ignoring case\n",
      "team CHA\n",
      "error 'Charlotte Hornets'\n",
      "Ignoring case\n",
      "team nan\n",
      "error None\n",
      "Ignoring case\n",
      "team CHA\n",
      "error 'Charlotte Hornets'\n",
      "Ignoring case\n",
      "team CHA\n",
      "error 'Charlotte Hornets'\n",
      "      +/-   3P%   AST  BLK   FG%    PTS   REB   STL   TOV   WIN% ... TOV_7  \\\n",
      "0    10.8  41.6  28.9  6.1  48.7  114.9  46.2   8.4  15.2   0.89 ...     1   \n",
      "1     0.2  34.7  22.2  5.2  45.2  106.5  43.1    10  15.9    0.5 ...   0.8   \n",
      "2     7.3  34.9    23  5.9  47.6  110.2  48.6   7.4  15.9  0.671 ...   1.4   \n",
      "3    -2.5  35.9  24.5  4.5  46.4  106.6  44.2   8.9  16.2  0.402 ...     0   \n",
      "4       6  36.2  22.7  3.9    46  104.3  44.5   6.7  13.6  0.695 ...   1.5   \n",
      "5     0.8    37  21.3  4.6    45  105.1  45.5   6.9  14.6  0.537 ...   0.8   \n",
      "6    -3.8    36  22.2  4.2  44.8  102.7  42.6   7.7  13.4  0.366 ...   1.7   \n",
      "7     4.5    37  18.7  5.5  45.1  102.7  43.4   7.8  13.1  0.683 ...   0.6   \n",
      "8     1.7  35.1  21.2  4.8    45  102.2  44.2     9  14.9  0.549 ...   1.3   \n",
      "9     3.2  33.5  24.2  4.2  43.9  105.7  44.9   9.2  13.7  0.585 ...   1.2   \n",
      "10   -2.7  34.6  20.5  5.7  43.9   98.4  44.4   5.7  13.4   0.39 ...     1   \n",
      "11    4.3  36.4  22.8  5.6  46.5  104.5    42   8.6    13  0.646 ...   0.9   \n",
      "12   10.6  37.5  24.5  5.9  48.4  103.5  43.9   8.3  13.1  0.817 ...     1   \n",
      "13   -1.5  37.1  22.8  5.7  44.1  101.6  46.3     6  13.9  0.512 ...   0.8   \n",
      "14   -3.5  33.8  23.4  4.6  46.4  102.4  41.6     8    15  0.354 ...   0.4   \n",
      "15   -7.4  35.2  22.3    4  45.3   98.6  42.4   7.6  14.8  0.256 ...   0.6   \n",
      "16   -6.7  34.8  20.7  3.8  43.5  100.9  44.8   7.7  17.2   0.28 ...   0.7   \n",
      "17   -0.5  35.8  24.5  3.9    46  104.1  41.8   8.6  14.5    0.5 ...   0.8   \n",
      "18    1.8  35.5    19  5.2  44.9   97.7  43.2   7.7  14.9  0.488 ...     1   \n",
      "19   -3.1  33.8  22.7  4.8  44.2  101.9  44.6   7.4  14.7  0.402 ...   0.9   \n",
      "20    1.6  33.6  20.8  6.5    47    100  44.1   6.7  14.1  0.585 ...   1.2   \n",
      "21    0.6  34.5  19.4  3.7  43.9    102  46.3     7  13.5  0.537 ...   0.4   \n",
      "22   -0.3  34.4  22.1  3.7  44.4  102.3  43.1   6.8  12.8  0.512 ...   1.5   \n",
      "23   -1.6    35  23.6  5.1  45.5  102.1  43.3   8.2  14.1  0.427 ...   0.8   \n",
      "24   -4.2  34.5  23.1  5.8  46.7     99  41.7   8.2  15.2  0.402 ...   1.8   \n",
      "25   -9.6  31.7    18  4.1  41.4   97.3    43   7.2  13.7  0.207 ...   0.5   \n",
      "26  -10.2  33.9  21.5    6  43.1   97.4  41.2   8.3  16.4  0.122 ...   1.2   \n",
      "27    3.6    35  25.6  5.9  45.8  102.8  42.1   9.1    15  0.585 ...   2.3   \n",
      "28   -2.2  33.1  20.7  4.3    44   99.1  41.6   8.8  13.3  0.512 ...   0.6   \n",
      "29    6.1  35.8  18.5  8.2  47.1  103.1  43.7   7.5  16.3  0.712 ...     1   \n",
      "..    ...   ...   ...  ...   ...    ...   ...   ...   ...    ... ...   ...   \n",
      "549  -4.2  33.4  20.8  5.3  44.2   92.2  42.1   7.8  16.5  0.366 ...   1.6   \n",
      "550   0.1  35.7  20.4  3.7  43.6   98.5  40.9   8.5  14.4  0.512 ...   1.2   \n",
      "551   2.3  35.6  23.3  5.7  45.1  100.4  44.3   7.8  14.5   0.61 ...   0.8   \n",
      "552   2.3  31.1  21.6  3.5  44.8   96.8  42.2  10.3  14.8  0.585 ...   1.2   \n",
      "553  -0.4  33.4  19.2  3.7  41.5   92.7  40.5   8.8    14  0.537 ...   0.9   \n",
      "554   7.8  38.1  22.4  5.5  45.3    103  42.1   8.1  11.6  0.732 ...   0.8   \n",
      "555   5.4  35.4    20  6.5  46.2   95.8  42.6   7.7  15.8  0.732 ...   1.4   \n",
      "556   6.5  38.1  24.8  5.6  46.4  101.7  44.5     9  14.5   0.72 ...   1.2   \n",
      "557   2.1  36.8  25.2  5.3  46.6   98.1  43.6   6.7  13.7  0.622 ...   0.8   \n",
      "558  -0.1  35.3  21.6  3.6  43.7   92.1  40.8   8.3  13.2  0.488 ...   0.8   \n",
      "559  -1.4  38.3    22  3.1  44.1   95.9  39.2   7.1    14  0.451 ...   1.4   \n",
      "560   1.1  34.3    21  4.9  44.3   95.5  42.5   8.1  14.7  0.537 ...   1.1   \n",
      "561  -1.1  34.4  20.9  6.2  44.1  102.4  46.7   7.2  15.8  0.463 ...   1.5   \n",
      "562  -5.1    35  21.7  5.6  44.5     95    43   7.4  16.9  0.366 ...   1.5   \n",
      "563   2.1  37.6    22  4.8  43.5   93.9  43.6     8  14.8  0.573 ...   1.2   \n",
      "564    -1  31.2  19.7  4.8    44   91.5  40.4   7.6  13.4  0.451 ...   1.4   \n",
      "565   1.5  34.6  18.4    6    44   93.8  43.8   7.2  15.6  0.524 ...   1.5   \n",
      "566  -3.6  35.2  20.5  5.8  44.4   94.1  42.6   7.5  16.7  0.427 ...   0.7   \n",
      "567   3.5  33.9  23.3  5.4  44.1   96.8  44.2   8.5  14.8  0.585 ...   0.8   \n",
      "568  -9.6  32.7  20.9  6.4  42.2   91.4  44.6   7.8  18.3  0.207 ...   1.6   \n",
      "569   2.4  34.9  25.6  5.7  46.8   94.7  41.5   8.6  16.8  0.573 ...   0.9   \n",
      "570  -5.9  34.3  19.3  4.8  42.7   90.9  41.2   7.4  14.4  0.293 ...     2   \n",
      "571   0.2  38.3  22.2  4.2  45.7   99.5  39.5   7.6  12.7  0.512 ...   1.9   \n",
      "572   3.7  35.8  19.8  5.7    43   91.4  40.6   6.8  13.5   0.61 ...   0.6   \n",
      "573  -3.2  36.5  23.1  6.1  45.2   97.5  41.6   7.9  15.4  0.341 ...   1.5   \n",
      "574   5.2  33.2    23  4.6  44.1   95.4  42.9   8.7  14.8  0.598 ...   1.4   \n",
      "575    -5  31.6  18.3    4  41.2   85.6  41.6   7.2  14.2  0.305 ...   1.1   \n",
      "576  -4.1  33.1  19.6  5.6  43.7   93.8  42.3     7  15.7  0.329 ...   0.9   \n",
      "577  -8.3  27.8  21.2  5.1  41.1   84.2  42.4   8.7  18.5  0.207 ...   0.9   \n",
      "578   2.6    33  22.7  3.9    46   95.2  41.1   8.8  15.2   0.61 ...   1.5   \n",
      "\n",
      "    TOV_8 W_1 W_2 W_3 W_4 W_5 W_6 W_7 W_8  \n",
      "0     0.8  73  71  71  59  59  62  69  42  \n",
      "1     1.2  41  40  34  35  24  41  39  10  \n",
      "2     1.1  52  55  54  53  54  48  55  37  \n",
      "3     0.7  29  29  29  29  27  27   0  26  \n",
      "4     1.1   0  56  53  37  53  57  54  39  \n",
      "5     0.9  40  44  44  43  44  33  43  39  \n",
      "6     0.5  24  14  11  24  27   4  20  28  \n",
      "7     0.9  54  53  16  40  54  54  53  56  \n",
      "8     1.4  44  41  44  41  34  32  33  31  \n",
      "9     1.1  45  48  43  47  36  47  45  40  \n",
      "10    3.6  32  27  28  29  32  32  25   0  \n",
      "11    0.7  51  22  50  48  50  51  42  51  \n",
      "12    1.7  60  61  59  65  50  66  24  47  \n",
      "13    1.8  37  32  36  37  37  41  13  15  \n",
      "14    0.8  29  29  28  29  29  29  27  20  \n",
      "15    0.9  21  21  10  21  20  13  18   7  \n",
      "16    1.1  16  12  23  20  18  23  14  23  \n",
      "17    1.4  37  28  36  35  40  22  40  41  \n",
      "18    1.8  38  39  30  33  13  31  39  27  \n",
      "19    1.3  22  31  29  33  12  26  26  31  \n",
      "20    1.3  29  31  44  45  43  42  46   3  \n",
      "21    1.4  41  42  37  43  43  37  36  34  \n",
      "22      1  40  31  38  29  40  40  38  35  \n",
      "23    1.2  32  33  28  32  35  32  14  20  \n",
      "24    1.7  33  32  32  21  32  21  17   9  \n",
      "25    0.6  17  14  17  17  13  17   4  16  \n",
      "26    1.3   6  10  16  10  10   9  10   8  \n",
      "27    0.5  48  48  46  47  44  42  47  29  \n",
      "28    1.4  30  33  37  38  34   2  31  36  \n",
      "29      1  47  47  44  47  46  40  31  44  \n",
      "..    ...  ..  ..  ..  ..  ..  ..  ..  ..  \n",
      "549   0.9  30  30  13  24  30  15  28  17  \n",
      "550   1.4  39  42  14  42  30  25  41  17  \n",
      "551   0.5  50  45  50  49  48  45  39  37  \n",
      "552   0.8  48  48  45  37  47  38  21  45  \n",
      "553   0.8  42  42  44  37  34  44  32   7  \n",
      "554   0.6  59  53  60  52  48  36  59  56  \n",
      "555   0.8  60  60  60  59  45  57  50  40  \n",
      "556   1.3  49  51  57  38  59  45  58  45  \n",
      "557   1.6  51  35  49  47  51  51  30  30  \n",
      "558   0.9  37  42  37  36  40  44  35  28  \n",
      "559   1.4  36  37  36  37  36  32  31  37  \n",
      "560   0.8  43  44  44  34  44  43  12  18  \n",
      "561   1.1  38  38  38  37  38  38  29  34  \n",
      "562   0.8  30  28  26  28  30  28  15  22  \n",
      "563   0.6  47  28  43  45  47  36  31  47  \n",
      "564   0.8  31  37  29  34  34  36  35  31  \n",
      "565   0.8  39  42  35  43  34  41  32  37  \n",
      "566   0.7  34  35  26  34  30  32  35   5  \n",
      "567   1.4  44  43  42  43  38  48  43  40  \n",
      "568     2  16  17  15   8  16  17  17  15  \n",
      "569   1.9  47  44  47  46  47  47  12  47  \n",
      "570   1.2  24  19  18  24  21  21   6   1  \n",
      "571   1.1  37  37  40  33  40  42  36  24  \n",
      "572   0.9  45  50  50  45  50  42  47  43  \n",
      "573   1.1  28  28  24  25  23  21  26  27  \n",
      "574     1  48  48  46  35  46  48  15  49  \n",
      "575   0.9  17  24  25  24  24  25  19  24  \n",
      "576   0.6  22  13  27  15  18  15  20   9  \n",
      "577   1.6  16  17  17  35   9  12   6  16  \n",
      "578     1  44  47  44  41  48  32  48  47  \n",
      "\n",
      "[579 rows x 226 columns]\n",
      "579\n",
      "dict_keys(['1516', '1112', '9798', '1314', '1011', '1213', '1415', '0910', '1617', '0708', '9900', '0304', '0102', '9697', '0506', '9899', '0405', '0607', '0001', '0203', '0809', '1718'])\n",
      "Done generating features.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# headers for player stats\n",
    "#['+/-' '3P%' '3PA' '3PM' 'AGE' 'AST' 'BLK' 'DD2' 'DREB' 'FG%' 'FGA' 'FGM'\n",
    "# 'FP' 'FT%' 'FTA' 'FTM' 'GP' 'L' 'MIN' 'OREB' 'PF' 'PTS' 'REB' 'STL' 'TD3'\n",
    "# 'TOV' 'W']\n",
    "\n",
    "# headers for team stats\n",
    "# ['+/-' '3P%' 'AST' 'BLK' 'FG%' 'PTS' 'REB' 'STL' 'TOV' 'WIN%']\n",
    "team_headers = ['+/-', '3P%', 'AST', 'BLK', 'FG%', 'PTS', 'REB', 'STL', 'TOV', 'WIN%']\n",
    "player_headers = ['+/-', '3P%', '3PA', '3PM', 'AGE', 'AST', 'BLK', 'DD2', 'DREB', 'FG%', 'FGA', 'FGM',\n",
    "                  'FP', 'FT%', 'FTA', 'FTM', 'GP', 'L', 'MIN', 'OREB', 'PF', 'PTS', 'REB', 'STL', 'TD3',\n",
    "                  'TOV', 'W']\n",
    "\n",
    "name_reverse_dictionary = {}\n",
    "for key, value in team_name_dict.items():\n",
    "    name_reverse_dictionary[value] = key\n",
    "    \n",
    "name_reverse_dictionary['NOK'] = 'New Orleans Hornets'\n",
    "name_reverse_dictionary['NOH'] = 'New Orleans Hornets'\n",
    "name_reverse_dictionary['CHA'] = 'Charlotte Hornets'\n",
    "\n",
    "# prepare data\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "team_folder = cwd+'/teams/'\n",
    "player_folder = cwd+'/players/'\n",
    "\n",
    "teams_dict = {}\n",
    "players_dict = {}\n",
    "\n",
    "def get_next_season(season):\n",
    "    beginning = int(season[:2])\n",
    "    year = None\n",
    "    if beginning < 20:\n",
    "        year = beginning + 2000\n",
    "    else:\n",
    "        year = beginning + 1900\n",
    "    return str(year+1)[2:] + str(year+2)[2:]\n",
    "\n",
    "team_list = ['Houston Rockets', 'Toronto Raptors', 'Golden State Warriors', 'Boston Celtics', 'Philadelphia 76ers', \n",
    "             'Cleveland Cavaliers', 'Portland Trail Blazers', 'Indiana Pacers', 'Oklahoma City Thunder', \n",
    "             'New Orleans Pelicans', 'Utah Jazz', 'San Antonio Spurs', 'Minnesota Timberwolves', 'Denver Nuggets', \n",
    "             'Miami Heat', 'Milwaukee Bucks', 'Washington Wizards', 'Los Angeles Clippers', 'Detroit Pistons', 'Charlotte Hornets',\n",
    "             'Los Angeles Lakers', 'New York Knicks', 'Brooklyn Nets', 'Sacramento Kings', 'Chicago Bulls', \n",
    "             'Orlando Magic', 'Dallas Mavericks', 'Atlanta Hawks', 'Memphis Grizzlies', 'Phoenix Suns']\n",
    "\n",
    "\n",
    "def get_short_name(team):\n",
    "    return team_name_dict.get(team)\n",
    "\n",
    "def get_long_name(team):\n",
    "    return name_reverse_dictionary.get(team)\n",
    "\n",
    "def name_conversion(team):\n",
    "    team_dict = {}\n",
    "    team_dict['Vancouver Grizzlies'] = 'Memphis Grizzlies'\n",
    "    team_dict['Charlotte Hornets'] = 'New Orleans Hornets'\n",
    "    team_dict['Seattle SuperSonics'] = 'Oklahoma City Thunder'\n",
    "    team_dict['New Jersey Nets'] = 'Brooklyn Nets'\n",
    "    team_dict['New Orleans Hornets'] = 'New Orleans Pelicans'\n",
    "    team_dict['Charlotte Bobcats'] = 'Charlotte Hornets'\n",
    "    return team_dict.get(team)\n",
    "\n",
    "def next_season_team(team_long, season):\n",
    "    new_team = team_long\n",
    "    \n",
    "    if season == '0001' and team_long == 'Vancouver Grizzlies':\n",
    "        new_team = name_conversion(team_long)\n",
    "    elif season == '0102' and team_long == 'Charlotte Hornets':\n",
    "        new_team = name_conversion(team_long)\n",
    "    elif season == '0708' and team_long == 'Seattle SuperSonics':\n",
    "        new_team = name_conversion(team_long)\n",
    "    elif season == '1112' and team_long == 'New Jersey Nets':\n",
    "        new_team = name_conversion(team_long)\n",
    "    elif season == '1314' and team_long == 'Charlotte Bobcats':\n",
    "        new_team = name_conversion(team_long)\n",
    "    elif season == '1213' and team_long =='New Orleans Hornets':\n",
    "        new_team = name_conversion(team_long)\n",
    "    \n",
    "    return new_team\n",
    "\n",
    "def build_dictionaries():\n",
    "    print('Building dictionaries...')\n",
    "    \n",
    "    for file in os.listdir(team_folder):\n",
    "        season = str(file[-8:-4])\n",
    "        season_teams = build_team_dictionary(team_folder+file)\n",
    "        #print(season_teams.keys())\n",
    "        teams_dict[season] = season_teams\n",
    "\n",
    "    for file in os.listdir(player_folder):\n",
    "        season = str(file[-8:-4])\n",
    "        season_players = build_player_dictionary(player_folder+file)\n",
    "        player_dict = {}\n",
    "        players_dict[season] = season_players\n",
    "        \n",
    "    print('Done building dictionaries.')\n",
    "\n",
    "    print(players_dict.keys())\n",
    "    print(teams_dict.keys())\n",
    "\n",
    "build_dictionaries()\n",
    "    \n",
    "\n",
    "num_seasons = len(players_dict)\n",
    "\n",
    "\n",
    "highest_season = '1718'\n",
    "print(num_seasons)\n",
    "\n",
    "def feature_gen():\n",
    "    print('Generating features...')\n",
    "    i = 0\n",
    "    if len(teams_dict) == 0:\n",
    "        build_dictionaries()\n",
    "    \n",
    "    x_vec_length = None\n",
    "\n",
    "    x_matrix = pd.DataFrame({})\n",
    "    y_vec = []\n",
    "    y_vec_cts = []\n",
    "    \n",
    "    for season, t_dict in players_dict.items():\n",
    "        i += 1\n",
    "        #print(season)\n",
    "        #print(get_next_season(season))\n",
    "        if i >= num_seasons-1 or season == highest_season:\n",
    "            continue\n",
    "\n",
    "        next_season = get_next_season(season)\n",
    "\n",
    "        # for each season, generate feature vectors for each team\n",
    "        for t, t_stats in t_dict.items():\n",
    "            plyr_vec = top_players_vec(t_stats)\n",
    "\n",
    "            next_season_tname = next_season_team(get_long_name(t), season)\n",
    "            if get_long_name(t) == 'LA Clippers':\n",
    "                print(season)\n",
    "                print('LA Clippers')\n",
    "            try:\n",
    "                team_vec = team_stats_vec(teams_dict[season][get_long_name(t)])\n",
    "            except Exception as e:\n",
    "                print('Ignoring case')\n",
    "                print('team', t)\n",
    "                print('error', e)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                next_team_vec = team_stats_vec(teams_dict[next_season][next_season_tname])\n",
    "            except Exception as e:\n",
    "                print('Ignoring case')\n",
    "                print(e)\n",
    "                continue\n",
    "            # create performance categories for win percentage\n",
    "            next_s_t_winp = next_team_vec[-1]  # index for the win%\n",
    "            cts = next_s_t_winp\n",
    "            if next_s_t_winp >= 0.8:\n",
    "                next_s_t_winp = 4\n",
    "            elif next_s_t_winp >= 0.6:\n",
    "                next_s_t_winp = 3\n",
    "            elif next_s_t_winp >= 0.4:\n",
    "                next_s_t_winp = 2\n",
    "            elif next_s_t_winp >= 0.2:\n",
    "                next_s_t_winp = 1\n",
    "            else:\n",
    "                next_s_t_winp = 0\n",
    "\n",
    "#             print('plyr_vec', plyr_vec)\n",
    "#             print('team_vec', team_vec)\n",
    "#             print('next_team_vec', next_team_vec)\n",
    "\n",
    "            # Create headers\n",
    "            player_h_portion = [[x+'_1', x+'_2', x+'_3', x+'_4', x+'_5', x+'_6', x+'_7', x+'_8'] for x in player_headers]\n",
    "            player_labels = []\n",
    "            for l in player_h_portion:\n",
    "                player_labels += l\n",
    "\n",
    "            curr_headers = team_headers+player_labels\n",
    "\n",
    "            x_vec = np.concatenate((team_vec, plyr_vec))\n",
    "            #print(x_vec)\n",
    "            x_series = pd.DataFrame(np.reshape(x_vec, (1,len(x_vec))), columns = curr_headers)\n",
    "            #print(x_series)\n",
    "            x_vec_label = next_s_t_winp  # set label\n",
    "            x_vec_label_cts = cts\n",
    "\n",
    "            #x_matrix.extend(x_series)\n",
    "            x_matrix = pd.concat([x_matrix, x_series], ignore_index=True)\n",
    "            y_vec.append(x_vec_label)\n",
    "            y_vec_cts.append(x_vec_label_cts)\n",
    "\n",
    "            x_vec_length = len(x_vec)  # this needs to only be executed once\n",
    "\n",
    "    xdf = pd.DataFrame(x_matrix)\n",
    "    print(xdf)\n",
    "    ydf = pd.DataFrame(y_vec)\n",
    "    ycts_df = pd.DataFrame(y_vec_cts)\n",
    "    print(len(x_matrix))\n",
    "    print(players_dict.keys())\n",
    "    print('Done generating features.')\n",
    "    \n",
    "    return xdf, ydf, ycts_df\n",
    "\n",
    "xdf, ydf, ycts = feature_gen()\n",
    "\n",
    "xdf.to_csv('x_matrix.csv', sep=',')\n",
    "ydf.to_csv('y_vec.csv', sep=',')\n",
    "ycts.to_csv('y_cts_vec.csv', sep=',')\n",
    "\n",
    "#print(len(x_matrix), len(x_matrix[0]))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephenbrock/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.03\n",
      "Variance score: -0.09\n",
      "[-0.08291837 -0.01819669 -0.06809268 -0.17308367 -0.05405401]\n"
     ]
    }
   ],
   "source": [
    "# Linear regression model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "Xdf = pd.read_csv('x_matrix.csv', sep=',', dtype='float', index_col=0)\n",
    "ydf = pd.read_csv('y_cts_vec.csv', sep=',', dtype='float', index_col=0)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xdf, ydf, test_size=0.2, random_state=20)\n",
    "\n",
    "# Create linear regression object\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "nba_y_pred = lm.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "#print('Coefficients: \\n', lm.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, nba_y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, nba_y_pred))\n",
    "#rounded = np.rint(nba_y_pred)\n",
    "#print('Accuracy:', metrics.accuracy_score(y_test, rounded))\n",
    "\n",
    "# r2 = 1 - SS(Res)/SS(tot), where SS(Res) and SS(tot) are based on the test data\n",
    "# cross validation:\n",
    "scores = cross_val_score(linear_model.LinearRegression(), Xdf, ydf, cv=5, scoring='r2')\n",
    "print(scores)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ec7448e4445b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mXdf_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXdf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mXdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mXdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mx_poly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolynomial_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXdf_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mydf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1344\u001b[0m                                           self.include_bias)\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m             \u001b[0mXP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mXP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# polynomial regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "polynomial_features= PolynomialFeatures(degree=3)\n",
    "\n",
    "Xdf_norm = (Xdf-Xdf.min())/(Xdf.max()-Xdf.min())\n",
    "\n",
    "x_poly = polynomial_features.fit_transform(Xdf_norm)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_poly, ydf, test_size=0.2, random_state=20)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_poly_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_poly_pred))\n",
    "r2 = r2_score(y_test,y_poly_pred)\n",
    "print(rmse)\n",
    "print(r2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost multiclass classifier model\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import time\n",
    "# import warnings\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Xdf = pd.read_csv('x_matrix.csv', sep=',', dtype='float', index_col=0)\n",
    "# #Xdf = Xdf.values\n",
    "# ydf = pd.read_csv('y_vec.csv', sep=',', dtype='float', index_col=0)\n",
    "# #ydf = np.array(ydf).ravel()\n",
    "\n",
    "# # train test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(Xdf, ydf, test_size=0.3, random_state=20)\n",
    "\n",
    "# grid = {'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100,200,300],\n",
    "#                   'max_depth': [10,20,30]}\n",
    "\n",
    "# model = GridSearchCV(estimator=XGBClassifier(), param_grid=grid, cv=3)\n",
    "\n",
    "# print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# end = time.time()\n",
    "\n",
    "# print('Model fit time:', end-start)\n",
    "\n",
    "# print(\"Fit the xgboost model\")\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred_train = model.predict(X_train)\n",
    "# print('Test accuracy:', accuracy_score(y_test, y_pred))\n",
    "# print('Train accuracy:', accuracy_score(y_train, y_pred_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579\n",
      "405 174 405 174\n",
      "Model fit time: 12.48275089263916\n",
      "Fit the xgboost model\n",
      "Test r2_score: 0.3050010196602423\n",
      "Train r2_score: 0.695496641037599\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Regression model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "#min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "thrs = 9e-05\n",
    "\n",
    "\n",
    "Xdf = pd.read_csv('x_matrix.csv', sep=',', dtype='float', index_col=0)\n",
    "normalized_df=(Xdf-Xdf.min())/(Xdf.max()-Xdf.min())\n",
    "Xdf = normalized_df.values\n",
    "ydf = pd.read_csv('y_cts_vec.csv', sep=',', dtype='float', index_col=0)\n",
    "ydf = np.array(ydf).ravel()\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(Xdf,ydf)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "#print(pca.singular_values_) \n",
    "\n",
    "\n",
    "print(len(Xdf))\n",
    "\n",
    "#x_scaled = min_max_scaler.fit_transform(Xdf)\n",
    "#df = pandas.DataFrame(x_scaled)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xdf, ydf, test_size=0.3, random_state=20)\n",
    "\n",
    "grid = {'learning_rate': [0.01], 'n_estimators': [30,50,100],\n",
    "                  'max_depth': [5,7,10]}\n",
    "\n",
    "model = GridSearchCV(estimator=XGBRegressor(), param_grid=grid, cv=3)\n",
    "\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Model fit time:', end-start)\n",
    "\n",
    "print(\"Fit the xgboost model\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "print('Test r2_score:', r2_score(y_test, y_pred))\n",
    "print('Train r2_score:', r2_score(y_train, y_pred_train))\n",
    "# overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106d33470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "title = \"Learning Curves XGBoost Regression Tree\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = XGBRegressor(learning_rate= 0.01, max_depth= 10, n_estimators= 100)\n",
    "myplot = plot_learning_curve(estimator, title, Xdf, ydf, ylim=(0.2, 1), cv=cv, n_jobs=4)\n",
    "myplot.show()\n",
    "\n",
    "# title = r\"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
    "# # SVC is more expensive so we do a lower number of CV iterations:\n",
    "# cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "# estimator = SVC(gamma=0.001)\n",
    "# plot_learning_curve(estimator, title, X, y, (0.7, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Train accuracy:', accuracy_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.best_params_\n",
    "print(params)\n",
    "# {'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model file\n",
    "import pickle\n",
    "pickle.dump(model, open(\"model.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "Xdf = pd.read_csv('x_matrix.csv', sep=',', dtype='float', index_col=0)\n",
    "ydf = pd.read_csv('y_vec.csv', sep=',', dtype='int32', index_col=0)\n",
    "\n",
    "Xdf = Xdf.values\n",
    "ydf = np.array(ydf).ravel()\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = ydf.reshape(len(ydf), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xdf, onehot_encoded, test_size=0.3, random_state=20)\n",
    "input_dim = len(X_train[0])\n",
    "\n",
    "# find number of categories\n",
    "num_categories = max(ydf)+1\n",
    "\n",
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(input_dim, input_dim=input_dim, activation='relu'))\n",
    "model_nn.add(Dense(50, activation='relu'))\n",
    "model_nn.add(Dense(50, activation='relu'))\n",
    "model_nn.add(Dense(input_dim, activation='relu'))\n",
    "model_nn.add(Dense(num_categories, activation='softmax'))\n",
    "\n",
    "model_nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_nn.fit(X_train, y_train, epochs=200, batch_size=10, verbose=1)\n",
    "scores = model_nn.evaluate(x=X_test,y=y_test)\n",
    "print(\"Model performance:\")\n",
    "print(\"%s,%.3f%%\" % (model_nn.metrics_names[1], scores[1]*100))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model_nn.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
